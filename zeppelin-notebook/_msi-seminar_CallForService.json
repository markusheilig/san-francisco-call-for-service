{"paragraphs":[{"text":"%md ### Access spark variables\n- 'sc' refers to the 'SparkContext'\n- 'spark' refers to the 'SparkSession'","user":"anonymous","dateUpdated":"2018-05-13T15:29:53+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Access spark variables</h3>\n<ul>\n  <li>&lsquo;sc&rsquo; refers to the &lsquo;SparkContext&rsquo;</li>\n  <li>&lsquo;spark&rsquo; refers to the &lsquo;SparkSession&rsquo;</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212532_-815596475","id":"20180505-182232_100685251","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:53+0200","dateFinished":"2018-05-13T15:29:53+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:286"},{"text":"sc\nspark","user":"anonymous","dateUpdated":"2018-05-13T15:29:53+0200","config":{"tableHide":false,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res88: org.apache.spark.SparkContext = org.apache.spark.SparkContext@2a7e88ef\nres89: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1caec9c0\n"}]},"apps":[],"jobName":"paragraph_1525542212532_-815596475","id":"20180505-182426_1778627150","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:53+0200","dateFinished":"2018-05-13T15:29:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:287"},{"text":"%md ### Read dataset from csv file into a dataframe called 'df'\nWe will only use a small file with 10k entries for live demonstration","user":"anonymous","dateUpdated":"2018-05-13T15:29:53+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Read dataset from csv file into a dataframe called &lsquo;df&rsquo;</h3>\n<p>We will only use a small file with 10k entries for live demonstration</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212532_-815596475","id":"20180505-182704_370792577","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:53+0200","dateFinished":"2018-05-13T15:29:53+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:288"},{"text":"val csvFile = \"/Volumes/TranscendJetdriveLite330/htwg/master/sem4/seminar/scala-spark-mllib-demo/datasets/10k.csv\"\nvar df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csvFile)\n","user":"anonymous","dateUpdated":"2018-05-13T15:30:25+0200","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"csvFile: String = /Volumes/TranscendJetdriveLite330/htwg/master/sem4/seminar/scala-spark-mllib-demo/datasets/2015_2018.csv\ndf: org.apache.spark.sql.DataFrame = [Call Number: int, Unit ID: string ... 32 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212532_-815596475","id":"20180505-182727_211105288","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:53+0200","dateFinished":"2018-05-13T15:30:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:289"},{"text":"%md ### Rename column names\nColumns of the original dataset contain spaces and dashes -> lets remove them","user":"anonymous","dateUpdated":"2018-05-13T15:29:53+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Rename column names</h3>\n<p>Columns of the original dataset contain spaces and dashes -&gt; lets remove them</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212532_-815596475","id":"20180505-182905_417148239","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:54+0200","dateFinished":"2018-05-13T15:29:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:290"},{"text":"val newColumnNames = df.columns.map(_.replace(\" \", \"\").replace(\"-\", \"\"))\ndf = df.toDF(newColumnNames: _*)","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"newColumnNames: Array[String] = Array(CallNumber, UnitID, IncidentNumber, CallType, CallDate, WatchDate, ReceivedDtTm, EntryDtTm, DispatchDtTm, ResponseDtTm, OnSceneDtTm, TransportDtTm, HospitalDtTm, CallFinalDisposition, AvailableDtTm, Address, City, ZipcodeofIncident, Battalion, StationArea, Box, OriginalPriority, Priority, FinalPriority, ALSUnit, CallTypeGroup, NumberofAlarms, UnitType, Unitsequenceincalldispatch, FirePreventionDistrict, SupervisorDistrict, NeighborhooodsAnalysisBoundaries, Location, RowID)\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 32 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212533_-815981224","id":"20180505-183001_1663637001","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:54+0200","dateFinished":"2018-05-13T15:30:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:291"},{"text":"%md # Data Exploration","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Data Exploration</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525875626831_-592962109","id":"20180509-162026_973890669","dateCreated":"2018-05-09T16:20:26+0200","dateStarted":"2018-05-13T15:29:54+0200","dateFinished":"2018-05-13T15:29:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:292"},{"text":"df.printSchema()\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- CallNumber: integer (nullable = true)\n |-- UnitID: string (nullable = true)\n |-- IncidentNumber: integer (nullable = true)\n |-- CallType: string (nullable = true)\n |-- CallDate: string (nullable = true)\n |-- WatchDate: string (nullable = true)\n |-- ReceivedDtTm: string (nullable = true)\n |-- EntryDtTm: string (nullable = true)\n |-- DispatchDtTm: string (nullable = true)\n |-- ResponseDtTm: string (nullable = true)\n |-- OnSceneDtTm: string (nullable = true)\n |-- TransportDtTm: string (nullable = true)\n |-- HospitalDtTm: string (nullable = true)\n |-- CallFinalDisposition: string (nullable = true)\n |-- AvailableDtTm: string (nullable = true)\n |-- Address: string (nullable = true)\n |-- City: string (nullable = true)\n |-- ZipcodeofIncident: integer (nullable = true)\n |-- Battalion: string (nullable = true)\n |-- StationArea: integer (nullable = true)\n |-- Box: string (nullable = true)\n |-- OriginalPriority: string (nullable = true)\n |-- Priority: string (nullable = true)\n |-- FinalPriority: integer (nullable = true)\n |-- ALSUnit: boolean (nullable = true)\n |-- CallTypeGroup: string (nullable = true)\n |-- NumberofAlarms: integer (nullable = true)\n |-- UnitType: string (nullable = true)\n |-- Unitsequenceincalldispatch: integer (nullable = true)\n |-- FirePreventionDistrict: string (nullable = true)\n |-- SupervisorDistrict: string (nullable = true)\n |-- NeighborhooodsAnalysisBoundaries: string (nullable = true)\n |-- Location: string (nullable = true)\n |-- RowID: string (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1525875644339_1371596423","id":"20180509-162044_853751011","dateCreated":"2018-05-09T16:20:44+0200","dateStarted":"2018-05-13T15:30:01+0200","dateFinished":"2018-05-13T15:30:01+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:293"},{"text":"%md ### How many rows are stored in our dataset?","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many rows are stored in our dataset?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526217472771_917055901","id":"20180513-151752_269626276","dateCreated":"2018-05-13T15:17:52+0200","dateStarted":"2018-05-13T15:29:54+0200","dateFinished":"2018-05-13T15:29:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:294"},{"text":"df.count()","user":"anonymous","dateUpdated":"2018-05-13T15:30:01+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res91: Long = 917988\n"}]},"apps":[],"jobName":"paragraph_1526217438221_660566303","id":"20180513-151718_901568690","dateCreated":"2018-05-13T15:17:18+0200","dateStarted":"2018-05-13T15:30:01+0200","dateFinished":"2018-05-13T15:30:03+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:295"},{"text":"%md ### How many incidents per Call Type Group?","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many incidents per Call Type Group?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200509436_-1601222676","id":"20180513-103509_489153769","dateCreated":"2018-05-13T10:35:09+0200","dateStarted":"2018-05-13T15:29:54+0200","dateFinished":"2018-05-13T15:29:54+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:296"},{"text":"df.groupBy($\"CallTypeGroup\").count().orderBy($\"count\".desc).show(truncate = false)","user":"anonymous","dateUpdated":"2018-05-13T15:29:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------------------+------+\n|CallTypeGroup               |count |\n+----------------------------+------+\n|Potentially Life-Threatening|451335|\n|Non Life-threatening        |220394|\n|Alarm                       |216168|\n|Fire                        |29350 |\n|null                        |741   |\n+----------------------------+------+\n\n"}]},"apps":[],"jobName":"paragraph_1525875879991_603574678","id":"20180509-162439_614832005","dateCreated":"2018-05-09T16:24:39+0200","dateStarted":"2018-05-13T15:30:01+0200","dateFinished":"2018-05-13T15:30:06+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:297"},{"text":"%md ### How many neighbourhoods are defined in our dataset?","user":"anonymous","dateUpdated":"2018-05-13T15:29:55+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many neighbourhoods are defined in our dataset?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526201050635_320194718","id":"20180513-104410_786508983","dateCreated":"2018-05-13T10:44:10+0200","dateStarted":"2018-05-13T15:29:55+0200","dateFinished":"2018-05-13T15:29:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:298"},{"text":"df.select($\"NeighborhooodsAnalysisBoundaries\").distinct().count()\n","user":"anonymous","dateUpdated":"2018-05-13T15:30:03+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res93: Long = 42\n"}]},"apps":[],"jobName":"paragraph_1526201090598_1158775466","id":"20180513-104450_1710172090","dateCreated":"2018-05-13T10:44:50+0200","dateStarted":"2018-05-13T15:30:03+0200","dateFinished":"2018-05-13T15:30:11+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:299"},{"text":"%md ### How many incidents per neighborhood?","user":"anonymous","dateUpdated":"2018-05-13T15:29:55+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many incidents per neighborhood?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200562807_1231526945","id":"20180513-103602_1495682826","dateCreated":"2018-05-13T10:36:02+0200","dateStarted":"2018-05-13T15:29:55+0200","dateFinished":"2018-05-13T15:29:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:300"},{"text":"df.groupBy( $\"NeighborhooodsAnalysisBoundaries\").count().orderBy($\"count\".desc).show(100, truncate = false)","user":"anonymous","dateUpdated":"2018-05-13T15:29:55+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------------------+------+\n|NeighborhooodsAnalysisBoundaries|count |\n+--------------------------------+------+\n|Tenderloin                      |125365|\n|South of Market                 |93417 |\n|Mission                         |81817 |\n|Financial District/South Beach  |67101 |\n|Bayview Hunters Point           |45685 |\n|Sunset/Parkside                 |33387 |\n|Western Addition                |31928 |\n|Nob Hill                        |30352 |\n|Castro/Upper Market             |23999 |\n|Outer Richmond                  |23943 |\n|Hayes Valley                    |22715 |\n|North Beach                     |21215 |\n|West of Twin Peaks              |19048 |\n|Chinatown                       |18692 |\n|Pacific Heights                 |18683 |\n|Excelsior                       |17860 |\n|Marina                          |16900 |\n|Potrero Hill                    |15925 |\n|Bernal Heights                  |15621 |\n|Haight Ashbury                  |15340 |\n|Mission Bay                     |14269 |\n|Russian Hill                    |14251 |\n|Inner Sunset                    |13932 |\n|Lakeshore                       |13575 |\n|Inner Richmond                  |12616 |\n|Outer Mission                   |12376 |\n|Lone Mountain/USF               |11693 |\n|Oceanview/Merced/Ingleside      |11632 |\n|Visitacion Valley               |10534 |\n|Noe Valley                      |9532  |\n|Portola                         |8547  |\n|Japantown                       |7673  |\n|Presidio Heights                |7216  |\n|Treasure Island                 |6564  |\n|Golden Gate Park                |5404  |\n|Twin Peaks                      |5200  |\n|Presidio                        |4713  |\n|Glen Park                       |4381  |\n|None                            |1494  |\n|Seacliff                        |1433  |\n|McLaren Park                    |1051  |\n|Lincoln Park                    |909   |\n+--------------------------------+------+\n\n"}]},"apps":[],"jobName":"paragraph_1525876180847_2141460359","id":"20180509-162940_951123989","dateCreated":"2018-05-09T16:29:40+0200","dateStarted":"2018-05-13T15:30:07+0200","dateFinished":"2018-05-13T15:30:14+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:301"},{"text":"%md ### How many incidents per Call Type Group in Tenderloin?","user":"anonymous","dateUpdated":"2018-05-13T15:29:55+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many incidents per Call Type Group in Tenderloin?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200768181_586042529","id":"20180513-103928_997554462","dateCreated":"2018-05-13T10:39:28+0200","dateStarted":"2018-05-13T15:29:55+0200","dateFinished":"2018-05-13T15:29:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:302"},{"text":"df.where($\"NeighborhooodsAnalysisBoundaries\" === \"Tenderloin\").groupBy( $\"CallTypeGroup\").count().orderBy($\"count\".desc).show(100, truncate = false)","user":"anonymous","dateUpdated":"2018-05-13T15:29:55+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------------------+-----+\n|CallTypeGroup               |count|\n+----------------------------+-----+\n|Potentially Life-Threatening|70403|\n|Non Life-threatening        |31123|\n|Alarm                       |22541|\n|Fire                        |1239 |\n|null                        |59   |\n+----------------------------+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1525876365869_441096271","id":"20180509-163245_1044022011","dateCreated":"2018-05-09T16:32:45+0200","dateStarted":"2018-05-13T15:30:11+0200","dateFinished":"2018-05-13T15:30:18+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:303"},{"text":"%md ### How many incidents per year?\n(dataset starts in april '15 and ends in april '18')","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many incidents per year?</h3>\n<p>(dataset starts in april &rsquo;15 and ends in april &lsquo;18&rsquo;)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200819770_-2002319853","id":"20180513-104019_1156148271","dateCreated":"2018-05-13T10:40:19+0200","dateStarted":"2018-05-13T15:29:56+0200","dateFinished":"2018-05-13T15:29:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:304"},{"text":"import org.apache.spark.sql.functions._\ndf.withColumn(\"EntryDtTm\", unix_timestamp($\"EntryDtTm\", \"MM/dd/yyyy hh:mm:ss a\").cast(\"timestamp\"))\n.groupBy(year($\"EntryDtTm\").alias(\"Year\")).count().orderBy($\"Year\".desc).show()","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions._\n+----+------+\n|Year| count|\n+----+------+\n|2018| 77885|\n|2017|312468|\n|2016|303967|\n|2015|223668|\n+----+------+\n\n"}]},"apps":[],"jobName":"paragraph_1525876605319_-1628515680","id":"20180509-163645_1096178213","dateCreated":"2018-05-09T16:36:45+0200","dateStarted":"2018-05-13T15:30:14+0200","dateFinished":"2018-05-13T15:30:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:305"},{"text":"%md ### Which days in the year are the most critical?","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Which days in the year are the most critical?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200858159_-747992466","id":"20180513-104058_1317659724","dateCreated":"2018-05-13T10:40:58+0200","dateStarted":"2018-05-13T15:29:56+0200","dateFinished":"2018-05-13T15:29:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:306"},{"text":"import org.apache.spark.sql.functions._\ndf.withColumn(\"EntryDtTm\", unix_timestamp($\"EntryDtTm\", \"MM/dd/yyyy hh:mm:ss a\").cast(\"timestamp\"))\n.withColumn(\"DayOfMonth\", dayofmonth($\"EntryDtTm\"))\n.withColumn(\"MonthOfYear\", month($\"EntryDtTm\"))\n.where($\"CallTypeGroup\" === \"Potentially Life-Threatening\")\n.groupBy($\"MonthOfYear\", $\"DayOfMonth\")\n.count()\n.orderBy($\"count\".desc)\n.show(366, false)\n//df.select().groupBy(dayofyear($\"EntryDtTm\").alias(\"DayOfYear\")).count().orderBy($\"count\".desc).show()","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions._\n+-----------+----------+-----+\n|MonthOfYear|DayOfMonth|count|\n+-----------+----------+-----+\n|9          |2         |1831 |\n|1          |1         |1746 |\n|9          |1         |1611 |\n|2          |3         |1521 |\n|9          |3         |1491 |\n|4          |30        |1484 |\n|12         |9         |1424 |\n|3          |17        |1419 |\n|6          |26        |1398 |\n|9          |19        |1398 |\n|9          |6         |1396 |\n|6          |19        |1393 |\n|10         |8         |1391 |\n|2          |6         |1389 |\n|4          |10        |1382 |\n|3          |16        |1380 |\n|12         |14        |1374 |\n|3          |3         |1373 |\n|5          |1         |1372 |\n|6          |3         |1372 |\n|11         |1         |1371 |\n|2          |7         |1371 |\n|9          |18        |1369 |\n|5          |21        |1368 |\n|3          |26        |1366 |\n|1          |4         |1362 |\n|6          |8         |1362 |\n|2          |4         |1361 |\n|12         |2         |1361 |\n|6          |27        |1360 |\n|12         |12        |1358 |\n|3          |18        |1357 |\n|4          |20        |1354 |\n|9          |24        |1352 |\n|9          |20        |1352 |\n|9          |26        |1350 |\n|10         |7         |1349 |\n|10         |2         |1348 |\n|12         |8         |1348 |\n|7          |22        |1348 |\n|3          |31        |1347 |\n|1          |5         |1342 |\n|4          |2         |1342 |\n|2          |2         |1339 |\n|3          |7         |1336 |\n|1          |12        |1331 |\n|10         |5         |1329 |\n|5          |7         |1328 |\n|2          |28        |1327 |\n|6          |16        |1327 |\n|5          |4         |1325 |\n|2          |9         |1324 |\n|2          |15        |1324 |\n|5          |2         |1323 |\n|11         |18        |1321 |\n|4          |6         |1321 |\n|2          |21        |1320 |\n|2          |12        |1319 |\n|10         |9         |1318 |\n|3          |29        |1317 |\n|11         |3         |1316 |\n|6          |25        |1314 |\n|5          |15        |1314 |\n|3          |27        |1311 |\n|11         |11        |1311 |\n|3          |21        |1310 |\n|9          |23        |1310 |\n|12         |10        |1310 |\n|6          |9         |1310 |\n|3          |30        |1306 |\n|7          |7         |1306 |\n|6          |28        |1306 |\n|2          |10        |1305 |\n|1          |6         |1305 |\n|6          |22        |1304 |\n|6          |17        |1304 |\n|2          |18        |1304 |\n|3          |9         |1303 |\n|10         |1         |1302 |\n|1          |13        |1302 |\n|5          |17        |1301 |\n|4          |29        |1299 |\n|3          |2         |1297 |\n|5          |6         |1297 |\n|3          |8         |1297 |\n|2          |5         |1295 |\n|6          |14        |1293 |\n|10         |21        |1291 |\n|1          |8         |1290 |\n|9          |5         |1289 |\n|12         |5         |1289 |\n|6          |18        |1287 |\n|3          |10        |1287 |\n|8          |3         |1287 |\n|10         |6         |1286 |\n|4          |13        |1286 |\n|4          |18        |1284 |\n|4          |27        |1284 |\n|2          |25        |1283 |\n|1          |2         |1279 |\n|11         |13        |1278 |\n|4          |17        |1278 |\n|6          |5         |1277 |\n|10         |19        |1277 |\n|10         |29        |1276 |\n|5          |8         |1275 |\n|11         |4         |1274 |\n|1          |14        |1273 |\n|6          |1         |1272 |\n|4          |1         |1272 |\n|10         |26        |1271 |\n|1          |9         |1268 |\n|2          |8         |1268 |\n|1          |3         |1267 |\n|8          |1         |1267 |\n|5          |3         |1266 |\n|8          |8         |1266 |\n|4          |12        |1266 |\n|5          |31        |1265 |\n|6          |24        |1265 |\n|3          |24        |1264 |\n|5          |25        |1264 |\n|10         |4         |1263 |\n|12         |16        |1263 |\n|12         |11        |1262 |\n|7          |30        |1262 |\n|8          |19        |1260 |\n|8          |30        |1259 |\n|12         |30        |1258 |\n|11         |9         |1258 |\n|7          |11        |1257 |\n|12         |18        |1256 |\n|5          |14        |1256 |\n|7          |14        |1255 |\n|1          |15        |1255 |\n|9          |11        |1254 |\n|11         |6         |1253 |\n|2          |14        |1252 |\n|4          |4         |1249 |\n|4          |8         |1248 |\n|10         |28        |1248 |\n|4          |16        |1248 |\n|3          |12        |1247 |\n|10         |30        |1247 |\n|6          |21        |1246 |\n|10         |16        |1246 |\n|12         |1         |1246 |\n|1          |7         |1246 |\n|10         |10        |1245 |\n|3          |6         |1245 |\n|7          |28        |1244 |\n|5          |13        |1244 |\n|4          |14        |1243 |\n|2          |19        |1243 |\n|10         |24        |1242 |\n|5          |28        |1241 |\n|12         |29        |1240 |\n|9          |4         |1240 |\n|6          |20        |1240 |\n|8          |11        |1240 |\n|5          |29        |1239 |\n|3          |28        |1239 |\n|9          |8         |1238 |\n|8          |27        |1238 |\n|7          |16        |1238 |\n|6          |15        |1237 |\n|4          |22        |1236 |\n|3          |20        |1236 |\n|4          |23        |1234 |\n|1          |17        |1234 |\n|3          |15        |1233 |\n|2          |11        |1232 |\n|10         |3         |1231 |\n|1          |27        |1231 |\n|12         |28        |1230 |\n|5          |12        |1230 |\n|6          |2         |1229 |\n|1          |28        |1229 |\n|11         |21        |1229 |\n|2          |16        |1229 |\n|1          |30        |1228 |\n|9          |10        |1228 |\n|2          |1         |1228 |\n|4          |15        |1228 |\n|12         |21        |1228 |\n|6          |6         |1227 |\n|3          |23        |1227 |\n|1          |10        |1226 |\n|9          |30        |1226 |\n|9          |28        |1225 |\n|12         |13        |1225 |\n|8          |18        |1225 |\n|2          |24        |1225 |\n|2          |26        |1224 |\n|1          |23        |1224 |\n|12         |3         |1223 |\n|11         |12        |1223 |\n|6          |13        |1223 |\n|2          |13        |1223 |\n|6          |10        |1222 |\n|10         |14        |1222 |\n|3          |1         |1222 |\n|12         |31        |1220 |\n|9          |9         |1220 |\n|1          |19        |1220 |\n|5          |19        |1220 |\n|8          |31        |1219 |\n|4          |26        |1218 |\n|5          |22        |1217 |\n|3          |22        |1217 |\n|9          |16        |1216 |\n|9          |21        |1216 |\n|1          |25        |1216 |\n|3          |5         |1216 |\n|8          |5         |1216 |\n|9          |7         |1215 |\n|9          |25        |1215 |\n|2          |23        |1214 |\n|5          |5         |1213 |\n|10         |23        |1213 |\n|8          |4         |1213 |\n|5          |20        |1213 |\n|10         |15        |1212 |\n|8          |17        |1211 |\n|11         |22        |1211 |\n|6          |12        |1209 |\n|10         |27        |1209 |\n|7          |1         |1208 |\n|10         |12        |1207 |\n|8          |15        |1205 |\n|7          |15        |1204 |\n|12         |17        |1204 |\n|11         |20        |1204 |\n|11         |19        |1203 |\n|6          |29        |1203 |\n|4          |24        |1201 |\n|11         |2         |1201 |\n|3          |14        |1199 |\n|11         |8         |1199 |\n|12         |15        |1199 |\n|4          |3         |1199 |\n|12         |23        |1197 |\n|1          |11        |1196 |\n|3          |25        |1196 |\n|1          |26        |1196 |\n|4          |21        |1196 |\n|1          |18        |1196 |\n|9          |15        |1195 |\n|3          |4         |1195 |\n|12         |4         |1194 |\n|5          |23        |1192 |\n|8          |10        |1191 |\n|11         |16        |1190 |\n|12         |20        |1190 |\n|2          |27        |1190 |\n|4          |7         |1190 |\n|8          |22        |1189 |\n|7          |26        |1189 |\n|8          |28        |1188 |\n|5          |10        |1186 |\n|11         |10        |1186 |\n|10         |31        |1185 |\n|8          |20        |1185 |\n|6          |30        |1184 |\n|6          |7         |1184 |\n|10         |18        |1183 |\n|7          |20        |1183 |\n|11         |17        |1183 |\n|11         |5         |1180 |\n|9          |14        |1180 |\n|5          |26        |1179 |\n|1          |20        |1179 |\n|3          |19        |1179 |\n|4          |9         |1178 |\n|4          |5         |1177 |\n|8          |21        |1176 |\n|12         |6         |1176 |\n|8          |9         |1176 |\n|4          |19        |1176 |\n|1          |21        |1175 |\n|3          |11        |1174 |\n|2          |22        |1174 |\n|7          |9         |1172 |\n|7          |21        |1171 |\n|7          |25        |1171 |\n|12         |22        |1170 |\n|7          |13        |1168 |\n|9          |12        |1168 |\n|1          |24        |1168 |\n|5          |24        |1166 |\n|9          |27        |1166 |\n|8          |7         |1166 |\n|5          |27        |1166 |\n|6          |23        |1164 |\n|4          |28        |1163 |\n|10         |25        |1163 |\n|6          |4         |1163 |\n|1          |31        |1162 |\n|7          |8         |1161 |\n|12         |19        |1160 |\n|8          |6         |1160 |\n|8          |24        |1157 |\n|1          |16        |1157 |\n|8          |12        |1156 |\n|11         |29        |1155 |\n|5          |30        |1155 |\n|10         |13        |1154 |\n|9          |17        |1154 |\n|10         |11        |1152 |\n|6          |11        |1152 |\n|11         |14        |1150 |\n|8          |26        |1150 |\n|9          |29        |1149 |\n|7          |6         |1149 |\n|4          |11        |1148 |\n|12         |27        |1145 |\n|11         |15        |1144 |\n|5          |9         |1142 |\n|8          |2         |1138 |\n|7          |2         |1137 |\n|10         |22        |1135 |\n|8          |29        |1135 |\n|11         |28        |1134 |\n|10         |20        |1133 |\n|3          |13        |1131 |\n|7          |10        |1131 |\n|7          |31        |1128 |\n|7          |19        |1127 |\n|1          |29        |1127 |\n|7          |24        |1123 |\n|5          |18        |1120 |\n|7          |5         |1113 |\n|11         |7         |1113 |\n|7          |3         |1112 |\n|7          |17        |1112 |\n|8          |23        |1112 |\n|7          |12        |1109 |\n|12         |7         |1108 |\n|10         |17        |1108 |\n|5          |11        |1104 |\n|7          |27        |1103 |\n|7          |18        |1099 |\n|8          |16        |1098 |\n|11         |30        |1097 |\n|9          |22        |1089 |\n|12         |24        |1087 |\n|9          |13        |1085 |\n|7          |4         |1083 |\n|2          |20        |1081 |\n|2          |17        |1079 |\n|12         |25        |1078 |\n|8          |13        |1077 |\n|11         |26        |1076 |\n|7          |29        |1073 |\n|7          |23        |1069 |\n|4          |25        |1069 |\n|8          |25        |1065 |\n|8          |14        |1065 |\n|1          |22        |1055 |\n|11         |27        |1053 |\n|11         |25        |1045 |\n|11         |24        |1043 |\n|12         |26        |1030 |\n|5          |16        |1025 |\n|11         |23        |999  |\n|2          |29        |482  |\n+-----------+----------+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1525877896275_154236103","id":"20180509-165816_1652024678","dateCreated":"2018-05-09T16:58:16+0200","dateStarted":"2018-05-13T15:30:18+0200","dateFinished":"2018-05-13T15:30:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:307"},{"text":"%md ### Drop some data\nSome columns contain no values (null) -> lets drop them!","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Drop some data</h3>\n<p>Some columns contain no values (null) -&gt; lets drop them!</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212533_-815981224","id":"20180505-183052_1909174503","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:56+0200","dateFinished":"2018-05-13T15:29:56+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:308"},{"text":"df = df.na.drop(Array(\"CallType\", \"Priority\", \"CallTypeGroup\", \"EntryDtTm\"))","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 32 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212533_-815981224","id":"20180505-183232_1746008601","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:30:25+0200","dateFinished":"2018-05-13T15:30:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:309"},{"text":"%md ### Let's generate some more features","user":"anonymous","dateUpdated":"2018-05-13T15:29:56+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Let&rsquo;s generate some more features</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212534_-814826977","id":"20180505-183333_966739090","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:57+0200","dateFinished":"2018-05-13T15:29:57+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:310"},{"text":"import org.apache.spark.sql.functions._\n\ndf = df.withColumn(\"EntryDtTm\", unix_timestamp($\"EntryDtTm\", \"MM/dd/yyyy hh:mm:ss a\").cast(\"timestamp\"))\ndf = df.withColumn(\"HourOfDay\", hour($\"EntryDtTm\"))\ndf = df.withColumn(\"DayOfYear\", dayofyear($\"EntryDtTm\"))\ndf = df.na.drop(Array(\"HourOfDay\", \"DayOfYear\"))\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions._\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 32 more fields]\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 33 more fields]\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 34 more fields]\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 34 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212534_-814826977","id":"20180505-183846_1695411028","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:30:31+0200","dateFinished":"2018-05-13T15:30:33+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:311"},{"text":"%md ### Lets calculate the geohash!\n\n![alt text] (https://www.researchgate.net/profile/Wonhee_Cho2/publication/283853353/figure/fig8/AS:296711042945037@1447752833863/Expansion-steps-of-a-digital-map-using-geohash.png)","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Lets calculate the geohash!</h3>\n<p><img src=\"https://www.researchgate.net/profile/Wonhee_Cho2/publication/283853353/figure/fig8/AS:296711042945037@1447752833863/Expansion-steps-of-a-digital-map-using-geohash.png\" alt=\"alt text\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1526200933175_20090576","id":"20180513-104213_1927603522","dateCreated":"2018-05-13T10:42:13+0200","dateStarted":"2018-05-13T15:29:57+0200","dateFinished":"2018-05-13T15:29:57+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:312"},{"text":"import ch.hsr.geohash.GeoHash\nimport scala.collection.mutable.ListBuffer\n\nval pattern = \"-?\\\\d+\\\\.{1}\\\\d+\".r\nspark.udf.register(\"geohash\", (s: String) => {\n  var coords = new ListBuffer[String]\n  pattern.findAllMatchIn(s).foreach(m=>coords+=m.toString())\n  GeoHash.geoHashStringWithCharacterPrecision(coords.apply(0).toDouble, coords.apply(1).toDouble, 6)\n})\ndf = df.withColumn(\"geohash\", callUDF(\"geohash\", $\"Location\"))\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import ch.hsr.geohash.GeoHash\nimport scala.collection.mutable.ListBuffer\npattern: scala.util.matching.Regex = -?\\d+\\.{1}\\d+\nres102: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 35 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525686268728_1818572127","id":"20180507-114428_1539328779","dateCreated":"2018-05-07T11:44:28+0200","dateStarted":"2018-05-13T15:30:31+0200","dateFinished":"2018-05-13T15:30:35+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:313"},{"text":"%md ### Lets create our label column","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Lets create our label column</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212534_-814826977","id":"20180505-183954_520582890","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:57+0200","dateFinished":"2018-05-13T15:29:57+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:314"},{"text":"def cdfUDF = udf((finalDisposition: String) => {\n    Set(\"Code 2 Transport\",\n        \"Fire\",\n        \"Patient Declined Transport\",\n        \"Against Medical Advice\",\n        \"Medical Examiner\",\n        \"Multi-casualty Incident\").contains(finalDisposition)\n})\n\ndef hospitalUDF = udf((hospital: String) => {\n    if (hospital == null || hospital.isEmpty) false else true\n})\n\ndf = df.withColumn(\"isCriticalDispositionT\", cdfUDF(df(\"CallFinalDisposition\")))\n.withColumn(\"isHospitalTransportT\", hospitalUDF(df(\"HospitalDtTm\")))\n\nvar dfTemp = df.select($\"IncidentNumber\", $\"isHospitalTransportT\", $\"isCriticalDispositionT\")\ndfTemp = dfTemp.groupBy(\"IncidentNumber\")\n               .agg(collect_set('isCriticalDispositionT) as \"tmpCD\", collect_set('isHospitalTransportT) as \"tmpH\")\n               .withColumn(\"isCriticalDisposition\", array_contains('tmpCD, true))\n               .withColumn(\"isHospitalTransport\", array_contains('tmpH, true))\n               .drop(\"tmpCD\").drop(\"tmpH\")\ndf = df.join(dfTemp, Seq(\"IncidentNumber\"))\n\n// data processing - add the label column (label = 1 <==> CallTypeGroup = \"Potentially Life-Threatening\" otherwise label = 0)\ndf = df.withColumn(\"label\",\n    when($\"CallTypeGroup\" === \"Potentially Life-Threatening\" && ($\"isCriticalDisposition\" === true || $\"isHospitalTransport\" === true), 1).otherwise(0))\n\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"cdfUDF: org.apache.spark.sql.expressions.UserDefinedFunction\nhospitalUDF: org.apache.spark.sql.expressions.UserDefinedFunction\ndf: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 37 more fields]\ndfTemp: org.apache.spark.sql.DataFrame = [IncidentNumber: int, isHospitalTransportT: boolean ... 1 more field]\ndfTemp: org.apache.spark.sql.DataFrame = [IncidentNumber: int, isCriticalDisposition: boolean ... 1 more field]\ndf: org.apache.spark.sql.DataFrame = [IncidentNumber: int, CallNumber: int ... 39 more fields]\ndf: org.apache.spark.sql.DataFrame = [IncidentNumber: int, CallNumber: int ... 40 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212534_-814826977","id":"20180505-191344_1887559871","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:30:34+0200","dateFinished":"2018-05-13T15:30:39+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:315"},{"text":"%md ### How many incidents are life-threatening?","user":"anonymous","dateUpdated":"2018-05-13T15:29:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>How many incidents are life-threatening?</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525861199039_365165365","id":"20180509-121959_1979965776","dateCreated":"2018-05-09T12:19:59+0200","dateStarted":"2018-05-13T15:29:58+0200","dateFinished":"2018-05-13T15:29:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:316"},{"text":"val lifeThreatening = df.filter($\"label\" === 1).count()\nval percentage = lifeThreatening.toDouble / df.count()\nprintln(\"%.2f%% of all incidents are life-threatening\".format(percentage * 100))","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":true},"editorMode":"ace/mode/scala","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lifeThreatening: Long = 394078\npercentage: Double = 0.4296312770714976\n42.96% of all incidents are life-threatening\n"}]},"apps":[],"jobName":"paragraph_1525861263717_225024820","id":"20180509-122103_2091948310","dateCreated":"2018-05-09T12:21:03+0200","dateStarted":"2018-05-13T15:30:35+0200","dateFinished":"2018-05-13T15:31:28+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:317"},{"text":"%md ### Split dataframe in train & test set","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Split dataframe in train &amp; test set</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212537_-817520219","id":"20180505-191352_263390882","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:58+0200","dateFinished":"2018-05-13T15:29:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:318"},{"text":"val Array(train, test) = df.randomSplit(Array(0.8, 0.2), seed = 12345)","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, CallNumber: int ... 40 more fields]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, CallNumber: int ... 40 more fields]\n"}]},"apps":[],"jobName":"paragraph_1525542212537_-817520219","id":"20180505-191425_1484507720","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:30:39+0200","dateFinished":"2018-05-13T15:31:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:319"},{"text":"%md ### Convert categorical string values","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Convert categorical string values</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212538_-816365972","id":"20180505-192112_1556031880","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:58+0200","dateFinished":"2018-05-13T15:29:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:320"},{"text":"import org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\n\nval categoricalFeatures = Array(\"CallType\", \"Priority\", \"geohash\")\nval indexers = categoricalFeatures.map(cf => new StringIndexer().setInputCol(s\"$cf\").setOutputCol(s\"${cf}Index\"))\n\nval featureNames = Array(\"HourOfDay\", \"DayOfYear\") ++ indexers.map(_.getOutputCol)\nval assembler = new VectorAssembler().setInputCols(featureNames).setOutputCol(\"features\")\n\nval stages = indexers :+ assembler","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\ncategoricalFeatures: Array[String] = Array(CallType, Priority, geohash)\nindexers: Array[org.apache.spark.ml.feature.StringIndexer] = Array(strIdx_b49549ebad5b, strIdx_2f983a791eeb, strIdx_5f4020f0e491)\nfeatureNames: Array[String] = Array(HourOfDay, DayOfYear, CallTypeIndex, PriorityIndex, geohashIndex)\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_291016fdfff9\nstages: Array[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable}] = Array(strIdx_b49549ebad5b, strIdx_2f983a791eeb, strIdx_5f4020f0e491, vecAssembler_291016fdfff9)\n"}]},"apps":[],"jobName":"paragraph_1525542212538_-816365972","id":"20180505-191558_1612387672","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:31:28+0200","dateFinished":"2018-05-13T15:31:31+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:321"},{"text":"%md ### Show some pre statistics","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Show some pre statistics</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212540_-818674466","id":"20180505-192353_969897850","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:58+0200","dateFinished":"2018-05-13T15:29:58+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:322"},{"text":"val numFeatures = featureNames.length\nprintln(\"numFeatures --> \" + numFeatures)\nprintln(\"trainCount --> \" + train.count())\nprintln(\"testCount --> \" + test.count())\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:58+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numFeatures: Int = 5\nnumFeatures --> 5\ntrainCount --> 733496\ntestCount --> 183751\n"}]},"apps":[],"jobName":"paragraph_1525542212540_-818674466","id":"20180505-192456_599251436","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:31:29+0200","dateFinished":"2018-05-13T15:33:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:323"},{"text":"%md ### Create a RandomForest classifier","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Create a RandomForest classifier</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212540_-818674466","id":"20180505-192508_1546955132","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:59+0200","dateFinished":"2018-05-13T15:29:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:324"},{"text":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineStage\nimport org.apache.spark.ml.classification.RandomForestClassifier\n\nval randomForest: PipelineStage = {\n\n    val testPipe = new Pipeline().setStages(stages)\n    val testModel = testPipe.fit(df)\n    val testFrame = testModel.transform(df)\n    \n    //Find feature with max count for maxBins\n    var max:Long = 0\n    featureNames.foreach(feature => {\n      val count = testFrame.agg(countDistinct(feature).as(\"count\")).collectAsList().get(0).getAs[Long](0)\n      max = Math.max(max, count)\n    })\n\n    new RandomForestClassifier()\n        .setImpurity(\"gini\")\n        .setMaxDepth(20)\n        .setNumTrees(30)\n        .setFeatureSubsetStrategy(\"auto\")\n        .setSeed(5043)\n        .setMaxBins(max.toInt)\n}\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineStage\nimport org.apache.spark.ml.classification.RandomForestClassifier\nrandomForest: org.apache.spark.ml.PipelineStage = rfc_cf476d8e456c\n"}]},"apps":[],"jobName":"paragraph_1525542212540_-818674466","id":"20180505-192535_1809949257","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:31:31+0200","dateFinished":"2018-05-13T15:35:06+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:325"},{"text":"%md ### Create a MultiLayerPerceptron (MLP)","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Create a MultiLayerPerceptron (MLP)</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212540_-818674466","id":"20180505-192649_1409557580","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:59+0200","dateFinished":"2018-05-13T15:29:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:326"},{"text":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineStage\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier\n\nval mlp: PipelineStage = {\n  val layers = Array[Int](numFeatures, 4, 3, 2)\n  new MultilayerPerceptronClassifier()\n        .setLayers(layers)\n        .setBlockSize(64)\n        .setSeed(1234L)\n        .setMaxIter(100000000)\n}\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineStage\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier\nmlp: org.apache.spark.ml.PipelineStage = mlpc_421ba3ab4684\n"}]},"apps":[],"jobName":"paragraph_1525542212541_-819059215","id":"20180505-192850_1802112070","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:33:01+0200","dateFinished":"2018-05-13T15:35:08+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:327"},{"text":"%md ### Now we can train a model","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Now we can train a model</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212541_-819059215","id":"20180505-192912_1792393046","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:59+0200","dateFinished":"2018-05-13T15:29:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:328"},{"text":"val classifier = randomForest\nval pipeline = new Pipeline().setStages(stages :+ classifier)\nval model = pipeline.fit(train)\n","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"classifier: org.apache.spark.ml.PipelineStage = rfc_cf476d8e456c\npipeline: org.apache.spark.ml.Pipeline = pipeline_ba88d67ee635\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 459.0 failed 1 times, most recent failure: Lost task 3.0 in stage 459.0 (TID 21032, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:934)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:748)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:747)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:747)\n  at org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:563)\n  at org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:198)\n  at org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:137)\n  at org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:45)\n  at org.apache.spark.ml.Predictor.fit(Predictor.scala:96)\n  at org.apache.spark.ml.Predictor.fit(Predictor.scala:72)\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:153)\n  at org.apache.spark.ml.Pipeline$$anonfun$fit$2.apply(Pipeline.scala:149)\n  at scala.collection.Iterator$class.foreach(Iterator.scala:893)\n  at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n  at scala.collection.IterableViewLike$Transformed$class.foreach(IterableViewLike.scala:44)\n  at scala.collection.SeqViewLike$AbstractTransformed.foreach(SeqViewLike.scala:37)\n  at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:149)\n  ... 68 elided\nCaused by: java.lang.OutOfMemoryError: GC overhead limit exceeded\n"}]},"apps":[],"jobName":"paragraph_1525542212541_-819059215","id":"20180505-193004_1865233798","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:35:07+0200","dateFinished":"2018-05-13T15:49:52+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:329"},{"text":"%md ### Print Statistics","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Print Statistics</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212542_-817904968","id":"20180505-193145_339559320","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:29:59+0200","dateFinished":"2018-05-13T15:29:59+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:330"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\n\ndef printStatistics(what: String, result: DataFrame): Unit = {\n    print(s\"\\n\\n$what statistics:\\n\")\n    val predictionAndLabels = result.select(\"prediction\", \"label\")\n    val metrics = new MulticlassMetrics(predictionAndLabels.as[(Double, Double)].rdd)\n    val FPR = metrics.falsePositiveRate(0)\n    val TPR = metrics.truePositiveRate(0)\n\n    println(s\"Accuracy: ${metrics.accuracy}\")\n    println(s\"Confusion matrix: \\n${metrics.confusionMatrix}\")\n    println(s\"Precicion (How many selected items are relevant?): \\n${metrics.precision(0)}\")\n    println(s\"Recall (How many relevant items are selected?)): \\n${metrics.recall(0)}\")\n    println(s\"F-measure (best 1, worst 0): \\n${metrics.fMeasure(0)}\")\n    println(s\"Miss rate: \\n${1-TPR}\")\n    println(s\"False alarm rate: \\n${FPR}\")\n}\n\nval trainResult = model.transform(train)\nprintStatistics(\"Training\", trainResult)\n\nval testResult = model.transform(test)\nprintStatistics(\"Test\", testResult)","user":"anonymous","dateUpdated":"2018-05-13T15:29:59+0200","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":"org.apache.thrift.transport.TTransportException","apps":[],"jobName":"paragraph_1525542212542_-817904968","id":"20180505-193157_1933165927","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:35:08+0200","dateFinished":"2018-05-13T15:49:54+0200","status":"ERROR","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:266)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:250)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:373)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:406)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:331"},{"text":"%md ### Save model","user":"anonymous","dateUpdated":"2018-05-13T15:30:00+0200","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Save model</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1525542212543_-818289717","id":"20180505-193240_513348199","dateCreated":"2018-05-05T19:43:32+0200","dateStarted":"2018-05-13T15:30:00+0200","dateFinished":"2018-05-13T15:30:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:332"},{"text":"//val timestamp = System.currentTimeMillis / 1000\n//model.save(s\"models/myclassifier-$timestamp\")","user":"anonymous","dateUpdated":"2018-05-13T15:30:00+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":"org.apache.zeppelin.interpreter.InterpreterException: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused (Connection refused)","apps":[],"jobName":"paragraph_1525873303576_880532065","id":"20180509-154143_2005462846","dateCreated":"2018-05-09T15:41:43+0200","dateStarted":"2018-05-13T15:49:54+0200","dateFinished":"2018-05-13T15:49:54+0200","status":"ERROR","errorMessage":"java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat org.apache.thrift.transport.TSocket.open(TSocket.java:182)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:51)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:37)\n\tat org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:60)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:861)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:435)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.getClient(RemoteInterpreterProcess.java:92)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:352)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:406)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","progressUpdateIntervalMs":500,"$$hashKey":"object:333"},{"user":"anonymous","dateUpdated":"2018-05-13T15:30:00+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525875414793_-1727292167","id":"20180509-161654_97913669","dateCreated":"2018-05-09T16:16:54+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:334"}],"name":"/msi-seminar/CallForService","id":"2DC755BVB","angularObjects":{"2DDC279KC:shared_process":[],"2DBUP5EAS:shared_process":[],"2DAZDNX9N:shared_process":[],"2D9Z6Q5BJ:shared_process":[],"2DDBWDT9X:shared_process":[],"2DAUQWYX5:shared_process":[],"2DC5TJRKP:shared_process":[],"2DA5B17KJ:shared_process":[],"2DD7Q9MS4:shared_process":[],"2DBPCQ1J2:shared_process":[],"2DD5PF1G3:shared_process":[],"2DBT69MZS:shared_process":[],"2DDGMMBB8:shared_process":[],"2DDTG9RP1:shared_process":[],"2DD3Z2K6G:shared_process":[],"2DDQNK69K:shared_process":[],"2DAG3KW3X:shared_process":[],"2DBPKXJB4:shared_process":[],"2DBYT73V5:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}